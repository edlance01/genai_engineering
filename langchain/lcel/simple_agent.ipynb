{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91e5dcfe",
   "metadata": {},
   "source": [
    "Agents are the decision-making layer within LangChain that choose actions dynamically instead of following a fixed sequence.\n",
    "They analyze the userâ€™s request, determine which tool is appropriate, and invoke it at the right moment.\n",
    "Agents follow a cycle of reasoning, taking action, observing the result, and adjusting their next step.\n",
    "This allows them to handle tasks that require multiple steps or real-time decision refinement.\n",
    "Agents make AI applications flexible and autonomous, enabling behaviors such as problem solving, multi-step workflows, and tool-driven interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60637633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie \"Top Gun\" was released in 1986. When you raise 1986 to the power of 2, you get 3,944,196.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "# 1. Define your tools \n",
    "@tool\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"Use this to look up real-time information or facts about the world.\"\"\"\n",
    "    if \"Top Gun\" in query:\n",
    "        return \"Top Gun was released in 1986.\"\n",
    "    return \"Information not found.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Use this for any numerical calculations or math problems.\"\"\"\n",
    "    return str(eval(expression))\n",
    "\n",
    "\n",
    "tools = [search_web, calculator]\n",
    "\n",
    "# 2. Initialize the model\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# 3. Create the Agent \n",
    "# ---------------------------------------------------\n",
    "# create_agent is the 2026 standard. It doesn't need a Hub pull;\n",
    "# it internally builds a LangGraph state machine for you.\n",
    "# ---------------------------------------------------\n",
    "agent = create_agent(llm, tools=tools)  #\n",
    "\n",
    "# 4. Execute (Point 4 on your slide: Refinement & Multi-step)\n",
    "question = \"What is the year Top Gun was released, raised to the power of 2?\"\n",
    "\n",
    "# Use the standard LangChain invoke pattern\n",
    "# The output is a dictionary containing the conversation 'messages'\n",
    "result = agent.invoke({\"messages\": [(\"user\", question)]})  #\n",
    "\n",
    "# Print the final response\n",
    "print(result[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
