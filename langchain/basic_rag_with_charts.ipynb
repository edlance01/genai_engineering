{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "672c085a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5dbaab321ac4555af2afabe003f200d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/274 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7f4c8b75e44261a5907f0f290e58f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "import base64\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.stores import InMemoryStore\n",
    "\n",
    "# The explicit path for the MultiVectorRetriever\n",
    "# from langchain_community.retrievers import MultiVectorRetriever\n",
    "from langchain_classic.retrievers import MultiVectorRetriever\n",
    "\n",
    "# Dedicated package for Chroma is now standard in 2026\n",
    "from langchain_chroma import Chroma\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# 1. Extract Elements from PDF\n",
    "# Using 'hi_res' strategy is required for image/table extraction\n",
    "elements = partition_pdf(\n",
    "    filename=\"../docs/samplegraphs.pdf\",\n",
    "    extract_images_in_pdf=True,\n",
    "    infer_table_structure=True,\n",
    "    chunking_strategy=\"by_title\",\n",
    "    strategy=\"hi_res\",  # Required for image extraction\n",
    "    max_characters=4000,\n",
    "    new_after_n_chars=3800,\n",
    "    extract_image_block_output_dir=\"extracted_images\",\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Encoding Helper and Summarizer\n",
    "def encode_image(image_path):\n",
    "    \"\"\"Helper to convert image to base64 for GPT-4o.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def summarize_image(image_base64):\n",
    "    chat = ChatOpenAI(model=\"gpt-4o\", max_tokens=1024)\n",
    "    msg = chat.invoke(\n",
    "        [\n",
    "            HumanMessage(\n",
    "                content=[\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"Describe this chart in detail. Extract data points and trends.\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\"},\n",
    "                    },\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    return msg.content\n",
    "\n",
    "\n",
    "# 3. Setup Chroma and Multi-Vector Retriever\n",
    "# Decouples search (summaries) from response (raw images)\n",
    "vectorstore = Chroma(collection_name=\"chart_rag\", embedding_function=OpenAIEmbeddings())\n",
    "store = InMemoryStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "\n",
    "# 4. Process and Add to Stores\n",
    "image_paths = [\n",
    "    os.path.join(\"extracted_images\", f) for f in os.listdir(\"extracted_images\")\n",
    "]\n",
    "image_summaries = []\n",
    "img_ids = [str(uuid.uuid4()) for _ in image_paths]\n",
    "\n",
    "for img_path in image_paths:\n",
    "    b64_img = encode_image(img_path)\n",
    "    image_summaries.append(summarize_image(b64_img))\n",
    "\n",
    "# Add Summaries to Vector Store (Child)\n",
    "summary_docs = [\n",
    "    Document(page_content=s, metadata={id_key: img_ids[i]})\n",
    "    for i, s in enumerate(image_summaries)\n",
    "]\n",
    "retriever.vectorstore.add_documents(summary_docs)\n",
    "\n",
    "# Add Raw Data to Docstore (Parent)\n",
    "# We use .mset to map the IDs to the original content\n",
    "retriever.docstore.mset(list(zip(img_ids, image_paths)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
