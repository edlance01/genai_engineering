{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b91eb667",
   "metadata": {},
   "source": [
    "# Visualizing LLM Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5fd342",
   "metadata": {},
   "source": [
    "### Step 1: Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a775bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the client (Replace 'your-api-key' or use environment variables)\n",
    "client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cae382",
   "metadata": {},
   "source": [
    "### Testing Function\n",
    "Let's you toggle the temperature parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7344fc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_completion(prompt, temp):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",  # Or \"gpt-3.5-turbo\"\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temp,\n",
    "        max_tokens=50,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64af77dc",
   "metadata": {},
   "source": [
    "### Run the Experiment\n",
    "Deterministic (0.0), Balanced (0.7), and Creative (1.5). We will run the \"Balanced\" and \"Creative\" prompts twice to see if the model gives different answers (stochasticity). aka randomness or unpredictability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7799d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Complete this sentence in a unique way: 'The secret to a long life is...'\"\n",
    "\n",
    "# Dictionary to store our results\n",
    "results = {\n",
    "    \"Deterministic (0.0)\": [\n",
    "        get_llm_completion(prompt, 0.0),\n",
    "        get_llm_completion(prompt, 0.0),\n",
    "    ],\n",
    "    \"Balanced (0.7)\": [\n",
    "        get_llm_completion(prompt, 0.7),\n",
    "        get_llm_completion(prompt, 0.7),\n",
    "    ],\n",
    "    \"Creative (1.5)\": [\n",
    "        get_llm_completion(prompt, 1.5),\n",
    "        get_llm_completion(prompt, 1.5),\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4be1077",
   "metadata": {},
   "source": [
    "### Display and Analyze Results\n",
    "Format the output to compare how the variety increases as the temperature rises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a9a617d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Deterministic (0.0)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1: The secret to a long life is cultivating a garden of gratitude, where each day you plant seeds of kindness, water them with laughter, and bask in the sunshine of meaningful connections.\n",
      "Run 2: The secret to a long life is cultivating a garden of gratitude, where each day you plant seeds of kindness, water them with laughter, and bask in the sunshine of meaningful connections.\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Balanced (0.7)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1: The secret to a long life is finding joy in the simple moments and nurturing the relationships that fill your heart with love and laughter.\n",
      "Run 2: The secret to a long life is crafting a tapestry of meaningful relationships, where each thread represents a shared moment, a lesson learned, or a laughter echoed across time.\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Creative (1.5)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1: The secret to a long life is finding joy in everyday moments, cherishing time with loved ones, and staying curious like an ever-blooming flower.\n",
      "Run 2: finding joy in the small moments, nurturing relationships that make you laugh, and maintaining curiosity about the world around you.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for setting, outputs in results.items():\n",
    "    display(Markdown(f\"### {setting}\"))\n",
    "    print(f\"Run 1: {outputs[0]}\")\n",
    "    print(f\"Run 2: {outputs[1]}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b994e54e",
   "metadata": {},
   "source": [
    "### Interpreting the Ouput\n",
    "Why did this happen?\n",
    "When the LLM predicts the next token, it generates a list of \"Logits\" (raw scores).\n",
    "\n",
    "At 0.0 (Deterministic): The model effectively performs \"Greedy Decoding.\" It always picks the word with the absolute highest probability. You will notice Run 1 and Run 2 are likely identical.\n",
    "\n",
    "At 0.7 (Balanced): The model uses \"Weighted Sampling.\" It still favors the likely words but allows for some variety. Run 1 and Run 2 will likely be different but still make perfect sense.\n",
    "\n",
    "At 1.5 (Creative): The probability distribution is flattened. Even very unlikely words now have a \"fighting chance\" to be picked. This often results in more poetic, bizarre, or even nonsensical completions.\n",
    "\n",
    "Quick Guide for your Projects:\n",
    "0.0 - 0.3: Use for Extraction, Classification, Coding, and Q&A.\n",
    "\n",
    "0.5 - 0.8: Use for Chatbots, Email generation, and Summarization.\n",
    "\n",
    "1.0+: Use for Brainstorming, Poetry, and Fiction writing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4b4184",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "508e46cc",
   "metadata": {},
   "source": [
    "# Top-P vs Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8fe96c",
   "metadata": {},
   "source": [
    "### Definte the Top-P Experiment\n",
    "In this cell, we add a parameter for top_p. Note that when using Top-P, we usually keep Temperature at a neutral 1.0 to see its pure effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1ef5692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- top_p = 0.1 ---\n",
      "a hidden room filled with ancient artifacts and mysterious symbols. The air was thick with dust, and a faint glow emanated from a pedestal in the center\n",
      "\n",
      "--- top_p = 0.5 ---\n",
      "a hidden room filled with ancient artifacts and mysterious symbols. The air was thick with dust, and a faint glow emanated from a pedestal in the center\n",
      "\n",
      "--- top_p = 0.9 ---\n",
      "a hidden room filled with glowing crystals and ancient artifacts. The air was thick with mystery and the soft hum of magic. Each step the cat took illuminated\n",
      "\n",
      "--- top_p = 1.0 ---\n",
      "a hidden realm filled with shimmering lights and floating islands. Mystical creatures roamed freely, and a gentle breeze carried the scent of blooming flowers. The\n"
     ]
    }
   ],
   "source": [
    "prompt = \"The cat opened the door and discovered\"\n",
    "\n",
    "for top_p in [0.1, 0.5, 0.9, 1.0]:\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o\",\n",
    "        input=prompt,\n",
    "        max_output_tokens=30,\n",
    "        temperature=1.0,\n",
    "        top_p=top_p,\n",
    "    )\n",
    "\n",
    "    print(f\"\\n--- top_p = {top_p} ---\")\n",
    "    print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff65c5d2",
   "metadata": {},
   "source": [
    "### Understanding the Difference\n",
    "Temperature is a Rescaler: It changes the relative \"volume\" of every word. High temperature makes quiet (unlikely) words louder and loud (likely) words quieter.\n",
    "\n",
    "Top-P is a Truncator: It sorts all words by probability and draws a line once the sum reaches P. Any word below that line is discarded entirely, no matter how \"loud\" it was."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cde1743",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
