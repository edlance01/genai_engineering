{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e0217da",
   "metadata": {},
   "source": [
    "## Demo: Mastering LangChain Expression Language (LCEL)\n",
    "This series of demos is designed to accompany the Generative AI Engineering workshop. We will move beyond single LLM calls to explore Reasoning Dataflows.\n",
    "\n",
    "Key Objectives:\n",
    "* Runnables: Understanding the atomic unit of LCEL.\n",
    "* The Pipe Operator (|): Visualizing the dataflow from prompt to parser.\n",
    "* RAG Integration: Connecting models to external knowledge streams.\n",
    "* Parallelism & Control: Implementing ensemble-style intelligence and cost-aware routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f577c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete. Model Initialized.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "# !pip install langchain langchain-openai\n",
    "\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "# Initialize the Model as a Transform Function\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "print(\"Setup Complete. Model Initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877066b2",
   "metadata": {},
   "source": [
    "### The Basic Pipe Flow\n",
    "The Pipe Flow Concept\n",
    "In LCEL, we treat reasoning as flowing data. Instead of nested function calls, we use the pipe operator (|) to create a clear, traceable pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15523fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain Output: Why did the AI engineer bring a ladder to work?\n",
      "\n",
      "Because they wanted to reach new heights in machine learning!\n"
     ]
    }
   ],
   "source": [
    "# 1. Define the Prompt (Computational Object) [cite: 287]\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Tell me a brief professional joke about {topic}.\"\n",
    ")\n",
    "\n",
    "# 2. Define the Output Parser (Intelligence Filter) [cite: 301]\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 3. Construct the Chain using Pipe Flow\n",
    "# Flow: Input -> Prompt -> Model -> Parser\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# Execute the pipeline\n",
    "response = chain.invoke({\"topic\": \"AI Engineering\"})\n",
    "print(f\"Chain Output: {response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7c86c4",
   "metadata": {},
   "source": [
    "### Parallel Reasoning Pipelines\n",
    "**Parallelism and Ensemble Intelligence:**\n",
    "Real-world problems often require multi-step reasoning. LCEL allows us to run multiple reasoning paths simultaneouslyâ€”for example, generating an answer while a separate path critiques the reasoning or verifies facts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f66daaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel Result 1 (Joke): Why did the OpenAI model break up with its partner?\n",
      "\n",
      "Because it needed more \"training\" to understand their \"emotional contexts\"!\n",
      "Parallel Result 2 (Fact): OpenAI was founded in December 2015 with the mission of ensuring that artificial general intelligence (AGI) benefits all of humanity. The organization focuses on advancing digital intelligence in a way that is safe and aligned with human values.\n"
     ]
    }
   ],
   "source": [
    "# Define two different reasoning paths\n",
    "joke_chain = ChatPromptTemplate.from_template(\"Joke about {topic}\") | model | parser\n",
    "fact_chain = (\n",
    "    ChatPromptTemplate.from_template(\"One real fact about {topic}\") | model | parser\n",
    ")\n",
    "\n",
    "# Combine them into a Parallel Pipeline\n",
    "map_chain = RunnableParallel(joke=joke_chain, fact=fact_chain)\n",
    "\n",
    "# Execute both simultaneously\n",
    "results = map_chain.invoke({\"topic\": \"OpenAI\"})\n",
    "print(f\"Parallel Result 1 (Joke): {results['joke']}\")\n",
    "print(f\"Parallel Result 2 (Fact): {results['fact']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a90301",
   "metadata": {},
   "source": [
    "### Cost-Aware Routing\n",
    "**Cost-Aware Execution:**\n",
    "Not every task requires the most powerful model. With LCEL, we can implement Conditional Logic to route simple tasks to smaller models (like GPT-4o-mini) and complex reasoning to larger ones, optimizing the system economically.\n",
    "\n",
    "RunnableBranch allows the pipeline to adapt dynamically, routing simple queries to efficient routes and complex tasks to deeper reasoning paths. This is essential for Cost-Aware Execution, ensuring intelligence is economically optimized by routing simpler steps to smaller models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcf281fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Route Output: Hello! How can I assist you today?\n",
      "Complex Route Output: Parallel reasoning pipelines are a critical element of Logical and Computational Event Logic (LCEL), as they provide a framework for processing multiple streams of reasoning simultaneously. The structural implications of these pipelines in LCEL can be understood through several key aspects:\n",
      "\n",
      "1. **Concurrency**: The primary implication of parallel reasoning pipelines is the ability to conduct concurrent reasoning processes. This allows different logical pathways to be explored at the same time, enhancing the overall efficiency of logical inference and decision-making. As a result, complex scenarios can be analyzed more effectively, especially in real-time applications.\n",
      "\n",
      "2. **Modularity**: Parallel reasoning pipelines promote a modular structure within LCEL. Each pipeline can be designed to handle specific types of reasoning tasks or event processing. This modularity allows for easier updates, maintenance, and the integration of new reasoning modules without disrupting the entire system. It also enables specialized reasoning techniques to be employed within their own pipelines.\n",
      "\n",
      "3. **Scalability**: The parallel nature of the pipelines enhances scalability, allowing LCEL systems to handle increasing amounts of data or more complex reasoning tasks without a proportional increase in processing time. By adding more parallel pipelines, one can scale out the reasoning capabilities to meet demanding computational requirements.\n",
      "\n",
      "4. **Fault Tolerance**: In a parallel reasoning structure, if one pipeline encounters an issue or fails to produce a valid outcome, other pipelines can continue to operate independently. This inherent fault tolerance improves the reliability of the LCEL system, as it can still provide useful outputs even if some components experience difficulties.\n",
      "\n",
      "5. **Resources Management**: The structural design of parallel reasoning pipelines must consider resource allocation and management. Each pipeline consumes computational resources, and effective coordination is necessary to avoid bottlenecks or resource contention. Algorithms and heuristics can be implemented to optimize the flow and usage of resources across multiple pipelines.\n",
      "\n",
      "6. **Inter-pipeline Communication**: Parallel pipelines may need to communicate with one another, especially when shared data or conclusions from one pipeline can inform or influence the reasoning in another. This necessitates a well-defined communication protocol and data-sharing mechanisms to ensure coherence and consistency across the different processes.\n",
      "\n",
      "7. **Integration of Diverse Reasoning Strategies**: With parallel reasoning, it's possible to integrate various reasoning strategies and paradigms (e.g., rule-based, probabilistic, temporal) within an LCEL framework. Each pipeline can be dedicated to a different strategy, leading to richer and more nuanced inference capabilities.\n",
      "\n",
      "8. **Complexity Management**: While parallel pipelines enhance processing power, they can also increase the complexity of the overall system architecture. Designing and managing multiple interacting pipelines requires careful consideration of dependencies, data flows, and potential conflicts between reasoning processes.\n",
      "\n",
      "In summary, the structural implications of parallel reasoning pipelines in LCEL encompass a range of factors, including efficiency, modularity, scalability, fault tolerance, resource management, and the integration of diverse reasoning strategies. These factors collectively enhance the overall capability of LCEL systems in handling complex logical and computational tasks.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableBranch\n",
    "\n",
    "# To fix the ValueError, we must ensure the 'model' receives a string or message.\n",
    "# We wrap the model in a small chain that extracts the 'question' from the input dict.\n",
    "model_path = (lambda x: x[\"question\"]) | model\n",
    "\n",
    "# Define the routing logic\n",
    "# LCEL treats reasoning as flowing data; each step reshapes meaning [cite: 273, 274, 276]\n",
    "branch = RunnableBranch(\n",
    "    (lambda x: len(x[\"question\"]) < 20, model_path),  # Route simple queries\n",
    "    model_path,  # Default route for complex tasks\n",
    ")\n",
    "\n",
    "# Build the full pipeline\n",
    "# User input flows through as a 'Computational Object' [cite: 286, 287]\n",
    "full_chain = {\"question\": RunnablePassthrough()} | branch | parser\n",
    "\n",
    "# Test routing\n",
    "try:\n",
    "    simple_res = full_chain.invoke(\"Hi!\")\n",
    "    complex_res = full_chain.invoke(\n",
    "        \"Explain the structural implications of parallel reasoning pipelines in LCEL.\"\n",
    "    )\n",
    "\n",
    "    print(f\"Simple Route Output: {simple_res}\")\n",
    "    print(f\"Complex Route Output: {complex_res}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
