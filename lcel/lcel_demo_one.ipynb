{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e0217da",
   "metadata": {},
   "source": [
    "## Demo: Mastering LangChain Expression Language (LCEL)\n",
    "This series of demos is designed to accompany the Generative AI Engineering workshop. We will move beyond single LLM calls to explore Reasoning Dataflows.\n",
    "\n",
    "Key Objectives:\n",
    "* Runnables: Understanding the atomic unit of LCEL.\n",
    "* The Pipe Operator (|): Visualizing the dataflow from prompt to parser.\n",
    "* RAG Integration: Connecting models to external knowledge streams.\n",
    "* Parallelism & Control: Implementing ensemble-style intelligence and cost-aware routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f577c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete. Model Initialized.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "# !pip install langchain langchain-openai\n",
    "\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "# Initialize the Model as a Transform Function\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "print(\"Setup Complete. Model Initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877066b2",
   "metadata": {},
   "source": [
    "### The Basic Pipe Flow\n",
    "The Pipe Flow Concept\n",
    "In LCEL, we treat reasoning as flowing data. Instead of nested function calls, we use the pipe operator (|) to create a clear, traceable pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15523fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain Output: Why did the AI engineer bring a ladder to work?\n",
      "\n",
      "Because they heard the job required some high-level thinking!\n"
     ]
    }
   ],
   "source": [
    "# 1. Define the Prompt (Computational Object) [cite: 287]\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Tell me a brief professional joke about {topic}.\"\n",
    ")\n",
    "\n",
    "# 2. Define the Output Parser (Intelligence Filter) [cite: 301]\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 3. Construct the Chain using Pipe Flow\n",
    "# Flow: Input -> Prompt -> Model -> Parser\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# Execute the pipeline\n",
    "response = chain.invoke({\"topic\": \"AI Engineering\"})\n",
    "print(f\"Chain Output: {response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7c86c4",
   "metadata": {},
   "source": [
    "### Parallel Reasoning Pipelines\n",
    "**Parallelism and Ensemble Intelligence:**\n",
    "Real-world problems often require multi-step reasoning. LCEL allows us to run multiple reasoning paths simultaneouslyâ€”for example, generating an answer while a separate path critiques the reasoning or verifies facts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f66daaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel Result 1 (Joke): Why did OpenAI go to therapy? \n",
      "\n",
      "Because it had too many unresolved parameters!\n",
      "Parallel Result 2 (Fact): OpenAI was founded in December 2015 with the mission to ensure that artificial general intelligence (AGI) benefits all of humanity.\n"
     ]
    }
   ],
   "source": [
    "# Define two different reasoning paths\n",
    "joke_chain = ChatPromptTemplate.from_template(\"Joke about {topic}\") | model | parser\n",
    "fact_chain = (\n",
    "    ChatPromptTemplate.from_template(\"One real fact about {topic}\") | model | parser\n",
    ")\n",
    "\n",
    "# Combine them into a Parallel Pipeline\n",
    "map_chain = RunnableParallel(joke=joke_chain, fact=fact_chain)\n",
    "\n",
    "# Execute both simultaneously\n",
    "results = map_chain.invoke({\"topic\": \"OpenAI\"})\n",
    "print(f\"Parallel Result 1 (Joke): {results['joke']}\")\n",
    "print(f\"Parallel Result 2 (Fact): {results['fact']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a90301",
   "metadata": {},
   "source": [
    "### Cost-Aware Routing\n",
    "**Cost-Aware Execution:**\n",
    "Not every task requires the most powerful model. With LCEL, we can implement Conditional Logic to route simple tasks to smaller models (like GPT-4o-mini) and complex reasoning to larger ones, optimizing the system economically.\n",
    "\n",
    "RunnableBranch allows the pipeline to adapt dynamically, routing simple queries to efficient routes and complex tasks to deeper reasoning paths. This is essential for Cost-Aware Execution, ensuring intelligence is economically optimized by routing simpler steps to smaller models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcf281fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Route Output: Hello! How can I assist you today?\n",
      "Complex Route Output: Parallel reasoning pipelines in the context of LCEL (Logic-based Communication and Expression Language) and similar systems introduce both opportunities and challenges that can affect the structure and organization of the reasoning process. Here are some structural implications of utilizing parallel reasoning pipelines:\n",
      "\n",
      "1. **Modularity**: Parallel reasoning allows for the decomposition of complex problems into smaller, more manageable sub-problems. Each pipeline can independently address a specific aspect of reasoning, promoting a modular architecture that enhances maintainability and comprehension.\n",
      "\n",
      "2. **Increased Throughput**: By processing multiple reasoning tasks simultaneously, parallel pipelines can significantly increase the overall throughput of the system. This is particularly beneficial in environments requiring real-time decision-making or where large datasets need to be processed quickly.\n",
      "\n",
      "3. **Resource Allocation**: Structuring reasoning pipelines in parallel requires careful consideration of resource allocation. Computational resources, such as CPU and memory, need to be distributed effectively among the pipelines to avoid bottlenecks and ensure efficient operation.\n",
      "\n",
      "4. **Synchronization and Coordination**: A parallel approach often necessitates mechanisms for synchronization and coordination among pipelines. Results from different pipelines may need to be merged or compared, which requires structural elements to handle dependencies and manage shared resources.\n",
      "\n",
      "5. **Fault Tolerance**: The structural design of parallel reasoning pipelines can enhance fault tolerance. If one pipeline fails or produces erroneous results, the overall system may still function using outputs from other pipelines, assuming that adequate redundancy and error handling mechanisms are in place.\n",
      "\n",
      "6. **Complexity in Debugging and Testing**: While parallel reasoning can enhance performance, it also introduces complexity in debugging and testing processes. The interactions between parallel pipelines can lead to difficult-to-track errors, necessitating more sophisticated testing frameworks.\n",
      "\n",
      "7. **Dynamic Scaling**: The structure of parallel reasoning systems can often be designed to allow for dynamic scaling, where additional pipelines can be instantiated or activated based on the computational demands of a reasoning task at hand.\n",
      "\n",
      "8. **Improved Scalability**: With a well-structured parallel reasoning architecture, the system may be more scalable, as additional parallel pipelines can be added to handle larger datasets or more complex reasoning tasks without a complete redesign of the system.\n",
      "\n",
      "9. **Distributed Processing**: In many cases, parallel reasoning pipelines may be distributed across multiple nodes in a network. This introduces considerations related to network communication, latency, and data consistency, which must be structurally integrated into the system design.\n",
      "\n",
      "10. **Non-linear Reasoning Paths**: The use of parallel reasoning allows for the exploration of non-linear reasoning paths, where multiple hypotheses or solutions can be assessed concurrently. This can lead to more innovative solutions and insights that may be missed in a strictly sequential reasoning process.\n",
      "\n",
      "In summary, the structural implications of using parallel reasoning pipelines in LCEL involve considerations of modularity, resource management, synchronization, fault tolerance, and overall system complexity. Properly addressing these implications can result in a robust and efficient reasoning environment capable of handling complex logical tasks effectively.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableBranch\n",
    "\n",
    "# To fix the ValueError, we must ensure the 'model' receives a string or message.\n",
    "# We wrap the model in a small chain that extracts the 'question' from the input dict.\n",
    "model_path = (lambda x: x[\"question\"]) | model\n",
    "\n",
    "# Define the routing logic\n",
    "# LCEL treats reasoning as flowing data; each step reshapes meaning [cite: 273, 274, 276]\n",
    "branch = RunnableBranch(\n",
    "    (lambda x: len(x[\"question\"]) < 20, model_path),  # Route simple queries\n",
    "    model_path,  # Default route for complex tasks\n",
    ")\n",
    "\n",
    "# Build the full pipeline\n",
    "# User input flows through as a 'Computational Object' [cite: 286, 287]\n",
    "full_chain = {\"question\": RunnablePassthrough()} | branch | parser\n",
    "\n",
    "# Test routing\n",
    "try:\n",
    "    simple_res = full_chain.invoke(\"Hi!\")\n",
    "    complex_res = full_chain.invoke(\n",
    "        \"Explain the structural implications of parallel reasoning pipelines in LCEL.\"\n",
    "    )\n",
    "\n",
    "    print(f\"Simple Route Output: {simple_res}\")\n",
    "    print(f\"Complex Route Output: {complex_res}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
