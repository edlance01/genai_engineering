{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md66596922",
   "metadata": {},
   "source": [
    "# Notebook 1 - Data Cleaning & Noise Removal\n",
    "**LLM Data Processing Pipeline · Stage 1 of 3**\n",
    "\n",
    "This notebook covers the foundational steps that make raw text usable for model training:\n",
    "- Removing duplicates\n",
    "- Removing irrelevant content\n",
    "- Correcting spelling errors\n",
    "- Stripping noise (ads, symbols, corrupted text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md82939731",
   "metadata": {},
   "source": [
    "## 1.1 Setup & Sample Data\n",
    "\n",
    "We start with a small corpus of raw text that mimics what you'd scrape from the web —\n",
    "duplicates, noise, typos and all.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c61641306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw corpus size: 11 entries\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The quikc brown fox jumpd over the lazy dog.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LLMs learn from massive volumes of text data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLICK HERE!!! Buy now &gt;&gt;&gt; ad.example.com &lt;&lt;&lt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LLMs learn from massive volumes of text data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neural networks are the backbone of modern AI.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>##$$$random symbols%%^^&amp;&amp;** corrupted entry ###</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transformers changed natural language processi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Deep learning models require large datasets fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Visit our site: spam-site.xyz — FREE OFFERS!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0        The quikc brown fox jumpd over the lazy dog.\n",
       "1       LLMs learn from massive volumes of text data.\n",
       "2        CLICK HERE!!! Buy now >>> ad.example.com <<<\n",
       "3       LLMs learn from massive volumes of text data.\n",
       "4      Neural networks are the backbone of modern AI.\n",
       "5     ##$$$random symbols%%^^&&** corrupted entry ###\n",
       "6   Transformers changed natural language processi...\n",
       "7                                                    \n",
       "8                                                    \n",
       "9   Deep learning models require large datasets fo...\n",
       "10     Visit our site: spam-site.xyz — FREE OFFERS!!!"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Sample raw corpus — intentionally messy\n",
    "# -------------------------------------------------------------------\n",
    "raw_texts = [\n",
    "    \"The quikc brown fox jumpd over the lazy dog.\",\n",
    "    \"LLMs learn from massive volumes of text data.\",\n",
    "    \"CLICK HERE!!! Buy now >>> ad.example.com <<<\",\n",
    "    \"LLMs learn from massive volumes of text data.\",   # duplicate\n",
    "    \"Neural networks are the backbone of modern AI.\",\n",
    "    \"##$$$random symbols%%^^&&** corrupted entry ###\",\n",
    "    \"Transformers changed natural language processing forever.\",\n",
    "    \"\",                                                 # empty string\n",
    "    \"   \",                                              # whitespace only\n",
    "    \"Deep learning models require large datasets for training.\",\n",
    "    \"Visit our site: spam-site.xyz — FREE OFFERS!!!\",\n",
    "]\n",
    "\n",
    "df = pd.DataFrame({\"text\": raw_texts})\n",
    "print(f\"Raw corpus size: {len(df)} entries\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md30697163",
   "metadata": {},
   "source": [
    "## 1.2 Remove Duplicates\n",
    "\n",
    "Duplicates inflate the apparent dataset size and can cause the model to over-weight\n",
    "certain patterns — a subtle but real training problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c82889492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 1 duplicate(s). Remaining: 10 entries\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The quikc brown fox jumpd over the lazy dog.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LLMs learn from massive volumes of text data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLICK HERE!!! Buy now &gt;&gt;&gt; ad.example.com &lt;&lt;&lt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neural networks are the backbone of modern AI.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>##$$$random symbols%%^^&amp;&amp;** corrupted entry ###</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Transformers changed natural language processi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Deep learning models require large datasets fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Visit our site: spam-site.xyz — FREE OFFERS!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0       The quikc brown fox jumpd over the lazy dog.\n",
       "1      LLMs learn from massive volumes of text data.\n",
       "2       CLICK HERE!!! Buy now >>> ad.example.com <<<\n",
       "3     Neural networks are the backbone of modern AI.\n",
       "4    ##$$$random symbols%%^^&&** corrupted entry ###\n",
       "5  Transformers changed natural language processi...\n",
       "6                                                   \n",
       "7                                                   \n",
       "8  Deep learning models require large datasets fo...\n",
       "9     Visit our site: spam-site.xyz — FREE OFFERS!!!"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Drop exact duplicate rows and reset the index\n",
    "# -------------------------------------------------------------------\n",
    "df_deduped = df.drop_duplicates(subset=\"text\").reset_index(drop=True)\n",
    "\n",
    "removed = len(df) - len(df_deduped)\n",
    "print(f\"Removed {removed} duplicate(s). Remaining: {len(df_deduped)} entries\")\n",
    "df_deduped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md30881612",
   "metadata": {},
   "source": [
    "## 1.3 Remove Empty & Whitespace-Only Entries\n",
    "\n",
    "Blank rows contribute nothing to learning and can cause tokenizer errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c28499435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing empties: 8 entries\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The quikc brown fox jumpd over the lazy dog.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LLMs learn from massive volumes of text data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLICK HERE!!! Buy now &gt;&gt;&gt; ad.example.com &lt;&lt;&lt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neural networks are the backbone of modern AI.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>##$$$random symbols%%^^&amp;&amp;** corrupted entry ###</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Transformers changed natural language processi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Deep learning models require large datasets fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Visit our site: spam-site.xyz — FREE OFFERS!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0       The quikc brown fox jumpd over the lazy dog.\n",
       "1      LLMs learn from massive volumes of text data.\n",
       "2       CLICK HERE!!! Buy now >>> ad.example.com <<<\n",
       "3     Neural networks are the backbone of modern AI.\n",
       "4    ##$$$random symbols%%^^&&** corrupted entry ###\n",
       "5  Transformers changed natural language processi...\n",
       "6  Deep learning models require large datasets fo...\n",
       "7     Visit our site: spam-site.xyz — FREE OFFERS!!!"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Strip whitespace, then filter rows that are empty after stripping\n",
    "# -------------------------------------------------------------------\n",
    "df_deduped[\"text\"] = df_deduped[\"text\"].str.strip()\n",
    "df_clean = df_deduped[df_deduped[\"text\"].str.len() > 0].reset_index(drop=True)\n",
    "\n",
    "print(f\"After removing empties: {len(df_clean)} entries\")\n",
    "df_clean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md53863807",
   "metadata": {},
   "source": [
    "## 1.4 Noise Removal\n",
    "\n",
    "Noise = advertisements, random symbols, corrupted text, spam URLs.\n",
    "We use regex rules to flag and remove them. In production you'd combine regex with\n",
    "a trained classifier for higher precision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c88064194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flagged as noise:\n",
      "['CLICK HERE!!! Buy now >>> ad.example.com <<<', '##$$$random symbols%%^^&&** corrupted entry ###', 'Visit our site: spam-site.xyz — FREE OFFERS!!!']\n",
      "\n",
      "After noise removal: 5 entries\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Define noise patterns\n",
    "# -------------------------------------------------------------------\n",
    "NOISE_PATTERNS = [\n",
    "    r\"https?://\\S+\",           # URLs\n",
    "    r\"\\w+\\.(xyz|com|net|org)\b\",  # bare domain names\n",
    "    r\"(?:CLICK HERE|BUY NOW|FREE OFFER|>>>|<<<)\",  # ad phrases\n",
    "    r\"[#$%^&*]{3,}\",           # clusters of special characters\n",
    "    r\"(?i)!!!\",                # excessive exclamation\n",
    "]\n",
    "\n",
    "def is_noisy(text):\n",
    "    for pat in NOISE_PATTERNS:\n",
    "        if re.search(pat, text, re.IGNORECASE):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "df_clean[\"is_noise\"] = df_clean[\"text\"].apply(is_noisy)\n",
    "\n",
    "print(\"Flagged as noise:\")\n",
    "print(df_clean[df_clean[\"is_noise\"]][\"text\"].tolist())\n",
    "\n",
    "df_no_noise = df_clean[~df_clean[\"is_noise\"]].drop(columns=\"is_noise\").reset_index(drop=True)\n",
    "print(f\"\\nAfter noise removal: {len(df_no_noise)} entries\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md53352352",
   "metadata": {},
   "source": [
    "## 1.5 Spelling Correction\n",
    "\n",
    "Typos fragment the vocabulary — \"quikc\" and \"quick\" become separate tokens,\n",
    "wasting model capacity. We correct common misspellings using `pyspellchecker`.\n",
    "\n",
    "> **Note:** Spell-checking is expensive at scale. In practice, sub-word tokenizers\n",
    "> like BPE partially mitigate the impact of typos, so this step is dataset-dependent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c85978640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spelling corrections made:\n",
      "  BEFORE: The quikc brown fox jumpd over the lazy dog.\n",
      "  AFTER : The quick brown fox jump over the lazy dog.\n",
      "  BEFORE: LLMs learn from massive volumes of text data.\n",
      "  AFTER : alms learn from massive volumes of text data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The quick brown fox jump over the lazy dog.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alms learn from massive volumes of text data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neural networks are the backbone of modern AI.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transformers changed natural language processi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deep learning models require large datasets fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0        The quick brown fox jump over the lazy dog.\n",
       "1      alms learn from massive volumes of text data.\n",
       "2     Neural networks are the backbone of modern AI.\n",
       "3  Transformers changed natural language processi...\n",
       "4  Deep learning models require large datasets fo..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Spell-check word by word, correcting known misspellings\n",
    "# Install: pip install pyspellchecker\n",
    "# -------------------------------------------------------------------\n",
    "try:\n",
    "    from spellchecker import SpellChecker\n",
    "    spell = SpellChecker()\n",
    "\n",
    "    def correct_spelling(text):\n",
    "        words = text.split()\n",
    "        corrected = []\n",
    "        for word in words:\n",
    "            # Only correct purely alphabetic words to avoid breaking code/names\n",
    "            if word.isalpha():\n",
    "                correction = spell.correction(word)\n",
    "                corrected.append(correction if correction else word)\n",
    "            else:\n",
    "                corrected.append(word)\n",
    "        return \" \".join(corrected)\n",
    "\n",
    "    df_no_noise[\"text_corrected\"] = df_no_noise[\"text\"].apply(correct_spelling)\n",
    "\n",
    "    # Show changes\n",
    "    changed = df_no_noise[df_no_noise[\"text\"] != df_no_noise[\"text_corrected\"]]\n",
    "    print(\"Spelling corrections made:\")\n",
    "    for _, row in changed.iterrows():\n",
    "        print(f\"  BEFORE: {row['text']}\")\n",
    "        print(f\"  AFTER : {row['text_corrected']}\")\n",
    "\n",
    "    df_final = df_no_noise[[\"text_corrected\"]].rename(columns={\"text_corrected\": \"text\"})\n",
    "\n",
    "except ImportError:\n",
    "    print(\"pyspellchecker not installed — skipping spell correction.\")\n",
    "    print(\"Run: pip install pyspellchecker\")\n",
    "    df_final = df_no_noise[[\"text\"]]\n",
    "\n",
    "df_final.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md71279975",
   "metadata": {},
   "source": [
    "## 1.6 Summary\n",
    "\n",
    "| Step | Input rows | Output rows | Removed |\n",
    "|------|-----------|-------------|---------|\n",
    "| Raw data | 11 | 11 | — |\n",
    "| Deduplication | 11 | 10 | 1 duplicate |\n",
    "| Empty removal | 10 | 8 | 2 blanks |\n",
    "| Noise removal | 8 | 6 | 2 noisy rows |\n",
    "| Spell correction | 6 | 6 | — (text fixed) |\n",
    "\n",
    "The cleaned corpus is ready to be passed to **Notebook 2 — Text Normalization & Handling Missing Data**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
